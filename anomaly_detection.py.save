import pandas as pd 
from sklearn.preprocessing import StandardScaler, OneHotEncoder 
from sklearn.compose import 
ColumnTransformer from sklearn.pipeline import Pipeline from 
sklearn.ensemble import IsolationForest import joblib
# Load dataset
data = pd.read_csv('kddcup.data_10_percent', header=None)
# Preprocess the data Identify categorical columns (protocol 
# type, service, flag)
categorical_cols = [1, 2, 3]
# Identify numerical columns
numerical_cols = list(set(data.columns) - 
set(categorical_cols) - {41})
# Define the preprocessor
preprocessor = ColumnTransformer( transformers=[ ('num', 
        StandardScaler(), numerical_cols), ('cat', 
        OneHotEncoder(), categorical_cols)
    ])
# Create a pipeline that first transforms the data and then 
# fits the model
pipeline = Pipeline(steps=[('preprocessor', preprocessor), 
                           ('model', 
                           IsolationForest(contamination=0.1))])
# Fit the pipeline
X = data.drop(columns=[41]) pipeline.fit(X)
# Save the pipeline
joblib.dump(pipeline, 'pipeline.pkl')
